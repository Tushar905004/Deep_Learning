{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd0d51f-f9f2-43d6-ae60-0f02c6a7271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f26973-d2a0-4ae0-9950-bdaec3037256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>611857364396965889</td>\n",
       "      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n",
       "      <td>nocode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>614484565059596288</td>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>614746522043973632</td>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>614877582664835073</td>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>611932373039644672</td>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  611857364396965889  @aandraous @britishmuseum @AndrewsAntonio Merc...   \n",
       "1  614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n",
       "2  614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n",
       "3  614877582664835073  @Sofabsports thank you for following me back. ...   \n",
       "4  611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n",
       "\n",
       "  category  \n",
       "0   nocode  \n",
       "1    happy  \n",
       "2    happy  \n",
       "3    happy  \n",
       "4    happy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.read_csv('C:/Users/HP/Datasets/smile-annotations-final.csv',names=['id','text','category'])\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de61a15c-c674-4f88-a104-257cac496d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nocode               1572\n",
       "happy                1137\n",
       "not-relevant          214\n",
       "angry                  57\n",
       "surprise               35\n",
       "sad                    32\n",
       "happy|surprise         11\n",
       "happy|sad               9\n",
       "disgust|angry           7\n",
       "disgust                 6\n",
       "sad|disgust             2\n",
       "sad|angry               2\n",
       "sad|disgust|angry       1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9ac0b9-184a-4a81-92b7-b8d06c16b39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nocode          1572\n",
       "happy           1137\n",
       "not-relevant     214\n",
       "angry             57\n",
       "surprise          35\n",
       "sad               32\n",
       "disgust            6\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = datasets[~datasets['category'].str.contains('\\|')]\n",
    "datasets.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ea40dc-c0aa-40bd-b0d1-df18a3524af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=datasets[datasets['category']!='nocode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d7dbc4-adf7-490c-9232-917aa05b4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d37c4373-0b9e-48e4-b9cb-386f8ea3e605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'not-relevant', 'angry', 'disgust', 'sad', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categorie = datasets.category.unique()\n",
    "unique_categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36767e8d-453b-4a90-a1c2-ad895e1bbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelD = {}\n",
    "for index,category in enumerate(unique_categorie):\n",
    "    labelD[category] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a276180-208a-4d7f-89d9-223a9ca8ac93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'happy': 0,\n",
       " 'not-relevant': 1,\n",
       " 'angry': 2,\n",
       " 'disgust': 3,\n",
       " 'sad': 4,\n",
       " 'surprise': 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91adc031-382a-448d-b1f8-ab1c99eb9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['label']=datasets.category.replace(labelD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7a0c6b-a388-434f-86e9-d81ba6d7da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b844b79-2a43-44e6-980d-5de853040f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(datasets.index.values,\n",
    "                                                datasets.label.values,\n",
    "                                                test_size = 0.2,\n",
    "                                                random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16acacee-8646-47f4-b1a6-bd3e6a17e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['Datatype'] = ['not_set']*datasets.shape[0]\n",
    "datasets.loc[X_train, 'Datatype'] = 'train'\n",
    "datasets.loc[X_test, 'Datatype'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ec85c3-ec8d-4aa4-9a03-b242d3868cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>614484565059596288</td>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>614746522043973632</td>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>614877582664835073</td>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>611932373039644672</td>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>611570404268883969</td>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "1  614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n",
       "2  614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n",
       "3  614877582664835073  @Sofabsports thank you for following me back. ...   \n",
       "4  611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n",
       "5  611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n",
       "\n",
       "  category  label Datatype  \n",
       "1    happy      0     test  \n",
       "2    happy      0    train  \n",
       "3    happy      0    train  \n",
       "4    happy      0    train  \n",
       "5    happy      0    train  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e38f4390-0441-4fb0-bf2b-e5f9fb1a3503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>Datatype</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>test</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">disgust</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>test</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>test</th>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>907</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">not-relevant</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>test</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sad</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>test</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">surprise</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>test</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  text\n",
       "category     label Datatype           \n",
       "angry        2     test       15    15\n",
       "                   train      42    42\n",
       "disgust      3     test        1     1\n",
       "                   train       5     5\n",
       "happy        0     test      230   230\n",
       "                   train     907   907\n",
       "not-relevant 1     test       36    36\n",
       "                   train     178   178\n",
       "sad          4     test        7     7\n",
       "                   train      25    25\n",
       "surprise     5     test        8     8\n",
       "                   train      27    27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.groupby(['category','label','Datatype']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9c8a0cf-bbc6-4521-b307-4c9eabee8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f36a942-c260-4d7a-961b-2dbfc89e6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenzier = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85d5155e-2799-4eb2-a67d-fb9db82356b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenzier.batch_encode_plus(\n",
    "    datasets[datasets['Datatype']=='train'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length = True,\n",
    "    max_length = 256,\n",
    "    return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eb5cffd-14b7-40c4-819d-9abcc8a0b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_test = tokenzier.batch_encode_plus(\n",
    "    datasets[datasets['Datatype']=='test'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length = True,\n",
    "    max_length = 256,\n",
    "    return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7062676-14b0-4f4e-91d6-8db75464298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_id_train = encoded_data_train['input_ids']\n",
    "attention_mask_train = encoded_data_train['attention_mask']\n",
    "labels_trian = torch.tensor(datasets[datasets.Datatype == 'train'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0c40c79-ab98-4d55-8def-2eda27bf14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_id_test = encoded_data_test['input_ids']\n",
    "attention_mask_test = encoded_data_test['attention_mask']\n",
    "labels_test = torch.tensor(datasets[datasets.Datatype == 'test'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83385eb4-ba98-4b83-a686-77655354654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train=TensorDataset(inputs_id_train,attention_mask_train,labels_trian)\n",
    "datasets_test=TensorDataset(inputs_id_test,attention_mask_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0558cc59-6298-438f-b883-247a17646aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78172394-8565-42e8-9d2b-3f1e0120ec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model =BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels = len(labelD),\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33a2364e-851f-415f-bdae-151fcc15a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71c968bb-5c73-4727-a9a8-89b91f2e8d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03af7149-2c4a-48ad-acf0-6ffd4718fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(datasets_train, sampler = RandomSampler(datasets_train),\n",
    "                             batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63f5f914-e227-466e-91b3-3c82facca397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(datasets_test, sampler = RandomSampler(datasets_test),\n",
    "                             batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4254dd41-8360-474d-982f-bc9143f2ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW,get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f222689-2dee-4070-8f7d-f22e50a182e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                 lr=1e-5,\n",
    "                 eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32c9372c-3d98-4386-9d31-bb054c738d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                           num_warmup_steps=0,\n",
    "                                           num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cce8b67-e15a-4fab-b5c3-464eabc3232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_scores(pred,labels):\n",
    "    pred_data=np.argmax(pred,axis=1).flatten()\n",
    "    labels_data = labels.flatten()\n",
    "    return f1_score(labels_data,pred_data,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3350ced7-d7da-4714-9ce2-766744d673a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_labels(pred,labels):\n",
    "    labels_data_dict = {v:k for k, v in labelD.items()}\n",
    "    pred_data=np.argmax(pred,axis=1).flatten()\n",
    "    labels_data=labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_data):\n",
    "        y_preds = pred_data[labels_data == label] #preditions\n",
    "        y_tue= labels_data[labels_data ==label] #Actual Values\n",
    "        \n",
    "        print(\"Class Data: {}\".format(labels_data_dict[label]))\n",
    "        print(\"Accuracy Data: {}\".format(len(y_preds[y_preds == label]/len(y_tue))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8225966-5187-455f-a9e8-44da76d9e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44e21c75-b173-4cb4-ad33-b84e399f1615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1558164a-2dbc-4b2c-8d71-963e8e7e837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_validation):\n",
    "    model.eval()\n",
    "    \n",
    "    loss_evaluation = 0\n",
    "    predictions, actual_values = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_validation):\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':batch[0],\n",
    "                 'attention_mask':batch[1],\n",
    "                 'labels':batch[2]}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_evaluation +=loss.item() \n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        labels_ids = inputs['labels'].cpu().numpy()\n",
    "        \n",
    "        predictions.append(logits)\n",
    "        actual_values.append(labels_ids)\n",
    "        \n",
    "    loss_evaluation_average = loss_evaluation / len(dataloader_validation)\n",
    "    \n",
    "    predictions = np.concatenate(predictions,axis = 0)\n",
    "    actual_values = np.concatenate(actual_values, axis=0)\n",
    "    \n",
    "    return loss_evaluation_average,predictions,actual_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21313ffe-59e3-40fc-8df8-a87c119501a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6c261d15174711baa4a715d27ab4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\epoch{epoch}\n",
      "Training Loss: 0.8280087750707124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c205a1d152844df398d35ddff1953f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.671600377363329 \n",
      "F1 Scores: 0.7144554493949637\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1,epochs+1)):\n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train,\n",
    "                       desc = \"Epoch {:1d}\".format(epoch),\n",
    "                       leave = False,\n",
    "                       disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs ={'input_ids' : batch[0],\n",
    "                 'attention_mask': batch[1],\n",
    "                 'labels':batch[2]}\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total +=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(),1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'Training_loss':'{:3f}'.format(loss.item()/len(batch))})\n",
    "        \n",
    "    torch.save(model.state_dict(), \"C:/Users/HP/Datasets/Models/Bert_ft_epoch{}.model\".format(epoch))\n",
    "    tqdm.write(\"\\epoch{epoch}\")\n",
    "    \n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write(\"Training Loss: {}\".format(loss_train_avg))\n",
    "    \n",
    "    loss_average, pred, actualvalues = evaluate(dataloader_train)\n",
    "    validation_result = f1_scores(pred,actualvalues)\n",
    "    \n",
    "    tqdm.write(\"Validation Loss: {} \".format(loss_average))\n",
    "    tqdm.write(\"F1 Scores: {}\".format(validation_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dfda55a-caf9-4d7b-803d-e04c340a24c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                       num_labels = len(labelD),\n",
    "                                                       output_attentions = False,\n",
    "                                                       output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cf8074f-0a3a-4816-99e9-f2f1d86f1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict( torch.load('C:/Users/HP/Datasets/Models/Fintuned_bert_epoch_1_gpu_trained.model',\n",
    "            #map_location = torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a51b2e47-df5a-4608-be32-24eac7de26c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414c821801f44242afa4503139782b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,predictions,true_vals = evaluate(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6367298-a951-4b4a-8ca9-a064320303ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Data: happy\n",
      "Accuracy Data: 907\n",
      "Class Data: not-relevant\n",
      "Accuracy Data: 0\n",
      "Class Data: angry\n",
      "Accuracy Data: 0\n",
      "Class Data: disgust\n",
      "Accuracy Data: 0\n",
      "Class Data: sad\n",
      "Accuracy Data: 0\n",
      "Class Data: surprise\n",
      "Accuracy Data: 0\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_labels(predictions,true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01bab27-b5d1-4046-9cbd-15f1ab7f51c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
